{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0981c2-8d12-4743-86fa-c0f1a7cc0ef9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2d7cd05-816f-4af8-a5d4-abaffb16c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# stocks\n",
    "import yfinance as yf\n",
    "\n",
    "# fama french\n",
    "import statsmodels.api as sm\n",
    "from statsmodels import regression\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "# markowitz\n",
    "from sklearn.decomposition import PCA\n",
    "from TracyWidom import TracyWidom\n",
    "import cvxopt as opt\n",
    "from cvxopt import blas, solvers\n",
    "import cufflinks\n",
    "import mplfinance as mpf\n",
    "import plotly.tools as tls\n",
    "from plotly.graph_objs import *\n",
    "solvers.options['show_progress'] = False\n",
    "import rie_estimator\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405f50b8-0f96-43bb-80a6-5f744624f96e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install rie_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71142dab-84ce-4aba-8ba4-b401834a1b52",
   "metadata": {},
   "source": [
    "## Basic Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e69698-a5c5-4b24-b7e1-d4fa88cc4e91",
   "metadata": {},
   "source": [
    "Plan: \n",
    "1. Data gathering\n",
    "      - Randomly select 30 stocks from the S&P 500 \n",
    "      - Get data for each of the stocks from the past 3 years using yfinance.  \n",
    "      - Get the daily Fama-French factors from the Kenneth French website.\n",
    "2. Implement the PCA Markowitz portfolio optimization\n",
    "      - PCA on normalized returns\n",
    "      - Check if PC1 is significant using Tracy-Widow\n",
    "      - Get the portfolio that corresponds to PC1\n",
    "3. Implement the Fama-French three-factor model\n",
    "      - For each stock, run the standard time series regression for the Fama-French model. \n",
    "      - Get the covariance matrix from the residuals \n",
    "4. Compare the 2 portfolios against the efficient frontier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508c7645-3166-44e5-b261-994139f1defc",
   "metadata": {},
   "source": [
    "### Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a772028-3023-43b2-8788-239f6e9c404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the stocks\n",
    "headers = {\n",
    "    'User-Agent': (\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
    "        '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    )\n",
    "}\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\",\n",
    "    headers=headers\n",
    ")\n",
    "response.raise_for_status()\n",
    "tables = pd.read_html(response.text)\n",
    "\n",
    "if len(tables) > 0:\n",
    "    stocks_df = tables[0]\n",
    "\n",
    "# randomly selecting 30 stocks\n",
    "random_stocks = stocks_df['Symbol'].sample(n=30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4e62b2-2e64-430b-bb2e-62bf588a252f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# getting closing prices for the 30 stocks with batching\n",
    "start_date = '2022-08-31'\n",
    "end_date = '2025-08-31'\n",
    "\n",
    "# def download_stocks_in_batches(tickers, batch_size=5, delay=1):\n",
    "#     \"\"\"\n",
    "#     Download stock data in batches to avoid rate limiting\n",
    "#     \"\"\"\n",
    "#     all_data = {}\n",
    "    \n",
    "#     for i in range(0, len(tickers), batch_size):\n",
    "#         batch = tickers[i:i + batch_size]\n",
    "#         print(f\"Downloading batch {i//batch_size + 1}: {batch}\")\n",
    "        \n",
    "#         try:\n",
    "#             # Download the batch\n",
    "#             batch_data = yf.download(\n",
    "#                 batch,\n",
    "#                 start=start_date,\n",
    "#                 end=end_date,\n",
    "#                 progress=False\n",
    "#             )\n",
    "            \n",
    "#             # Extract closing prices for this batch\n",
    "#             if not batch_data.empty and 'Close' in batch_data.columns:\n",
    "#                 closes = batch_data['Close']\n",
    "#                 # Handle single ticker case (returns Series instead of DataFrame)\n",
    "#                 if isinstance(closes, pd.Series):\n",
    "#                     all_data[batch[0]] = closes\n",
    "#                 else:\n",
    "#                     for ticker in closes.columns:\n",
    "#                         all_data[ticker] = closes[ticker]\n",
    "#                 print(f\"Successfully downloaded {len(batch)} stocks\")\n",
    "#             else:\n",
    "#                 print(f\"No data returned for batch: {batch}\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error downloading batch {batch}: {e}\")\n",
    "        \n",
    "#         # Add delay between batches to avoid rate limiting\n",
    "#         if i + batch_size < len(tickers):\n",
    "#             print(f\"Waiting {delay} seconds before next batch...\")\n",
    "#             time.sleep(delay)\n",
    "    \n",
    "#     # Combine all data into a single DataFrame\n",
    "#     if all_data:\n",
    "#         return pd.DataFrame(all_data)\n",
    "#     else:\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "# # Download in batches of 5 stocks with 1-second delay\n",
    "# closing_df = download_stocks_in_batches(\n",
    "#     random_stocks.tolist(), \n",
    "#     batch_size=5, \n",
    "#     delay=15\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfda8275-d4e1-4883-af65-683fa6c509e2",
   "metadata": {},
   "source": [
    "This code above was generated with ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1161b60c-443d-4278-8384-ae4c7200a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not closing_df.empty:\n",
    "#     closing_df.to_pickle('closing prices.pkl')\n",
    "\n",
    "# closing_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9ed54b-979a-4745-b9cb-867db7dbcbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Donna\\AppData\\Local\\Temp\\ipykernel_10076\\114982135.py:4: DeprecationWarning:\n",
      "\n",
      "numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BR</th>\n",
       "      <th>CINF</th>\n",
       "      <th>DHI</th>\n",
       "      <th>K</th>\n",
       "      <th>LIN</th>\n",
       "      <th>BA</th>\n",
       "      <th>GLW</th>\n",
       "      <th>IDXX</th>\n",
       "      <th>LHX</th>\n",
       "      <th>O</th>\n",
       "      <th>...</th>\n",
       "      <th>BLDR</th>\n",
       "      <th>HCA</th>\n",
       "      <th>HSIC</th>\n",
       "      <th>WMB</th>\n",
       "      <th>WTW</th>\n",
       "      <th>CB</th>\n",
       "      <th>NWS</th>\n",
       "      <th>ROP</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VTRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-25</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-26</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-27</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-28</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-29</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              BR  CINF   DHI     K   LIN    BA   GLW  IDXX   LHX     O  ...  \\\n",
       "Date                                                                    ...   \n",
       "2022-09-01  0.00  0.01  0.00  0.01 -0.01 -0.04 -0.01  0.01  0.00  0.00  ...   \n",
       "2022-09-02 -0.03 -0.01  0.00 -0.01 -0.01 -0.01 -0.02 -0.02 -0.00 -0.01  ...   \n",
       "2022-09-06  0.01  0.00 -0.02 -0.01 -0.00  0.00 -0.01 -0.01  0.01  0.00  ...   \n",
       "2022-09-07  0.01  0.02  0.02  0.01  0.03  0.02  0.01  0.04  0.01  0.01  ...   \n",
       "2022-09-08  0.01  0.01  0.01 -0.02 -0.01  0.01  0.00  0.03  0.00 -0.03  ...   \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "2025-08-25 -0.02 -0.01 -0.01 -0.00 -0.01 -0.01  0.02 -0.01  0.00 -0.01  ...   \n",
       "2025-08-26  0.00  0.00 -0.00 -0.00  0.01  0.03  0.01  0.00  0.01 -0.00  ...   \n",
       "2025-08-27  0.00  0.00 -0.01 -0.00  0.00  0.00 -0.00 -0.00 -0.00  0.01  ...   \n",
       "2025-08-28 -0.00 -0.00  0.01 -0.00 -0.00  0.00  0.02  0.01  0.00 -0.01  ...   \n",
       "2025-08-29 -0.01  0.00  0.00  0.00 -0.01 -0.01 -0.02  0.00  0.00  0.01  ...   \n",
       "\n",
       "            BLDR   HCA  HSIC   WMB   WTW    CB   NWS   ROP   UNH  VTRS  \n",
       "Date                                                                    \n",
       "2022-09-01  0.00  0.01 -0.01 -0.01  0.00  0.02  0.00  0.01  0.01  0.00  \n",
       "2022-09-02 -0.00  0.00 -0.02  0.00 -0.01 -0.01  0.00 -0.01 -0.01 -0.01  \n",
       "2022-09-06 -0.02  0.00 -0.00 -0.02  0.00 -0.00 -0.03 -0.01  0.00 -0.00  \n",
       "2022-09-07  0.02  0.06  0.02  0.00  0.03  0.02  0.02  0.02  0.01  0.03  \n",
       "2022-09-08  0.00  0.02  0.01 -0.03  0.00  0.01 -0.00  0.00  0.01 -0.00  \n",
       "...          ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2025-08-25 -0.02 -0.01 -0.02 -0.00 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01  \n",
       "2025-08-26  0.01 -0.00  0.01  0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01  \n",
       "2025-08-27 -0.01  0.01 -0.00  0.01 -0.01  0.00 -0.01  0.01  0.01  0.00  \n",
       "2025-08-28 -0.01  0.01  0.00  0.01 -0.01  0.00 -0.00 -0.00 -0.01 -0.00  \n",
       "2025-08-29 -0.01 -0.01  0.01 -0.00 -0.00  0.01 -0.01 -0.00  0.02  0.01  \n",
       "\n",
       "[751 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opening pkl file\n",
    "filename = r'closing prices.pkl'\n",
    "with open(filename, 'rb') as f: \n",
    "    closing_df = pickle.load(f)\n",
    "    closing_df.index = pd.to_datetime(closing_df.index)\n",
    "\n",
    "# getting simple returns\n",
    "simple_df = closing_df / closing_df.shift()\n",
    "simple_df.dropna(how='all', inplace=True)\n",
    "\n",
    "# getting log returns\n",
    "log_df = np.log(simple_df)\n",
    "log_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c415700-691b-49db-a51f-2706ac79c666",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-01</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>-0.99</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06</th>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>1.92</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-25</th>\n",
       "      <td>-0.48</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-26</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-27</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-28</th>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-29</th>\n",
       "      <td>-0.68</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>751 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Mkt-RF   SMB   HML    RF\n",
       "date                                \n",
       "2022-09-01    0.00 -1.11 -0.28  0.01\n",
       "2022-09-02   -0.99 -0.06  1.03  0.01\n",
       "2022-09-06   -0.51 -0.45 -0.54  0.01\n",
       "2022-09-07    1.92  0.71 -1.53  0.01\n",
       "2022-09-08    0.78 -0.08 -0.18  0.01\n",
       "...            ...   ...   ...   ...\n",
       "2025-08-25   -0.48 -0.63  0.45  0.02\n",
       "2025-08-26    0.43  0.25  0.13  0.02\n",
       "2025-08-27    0.24  0.40  0.27  0.02\n",
       "2025-08-28    0.35 -0.15 -0.52  0.02\n",
       "2025-08-29   -0.68  0.02  0.85  0.02\n",
       "\n",
       "[751 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting fama french factors\n",
    "ff_data = pd.read_csv(\n",
    "    'ff_factors.csv', \n",
    "    header=3\n",
    ")\n",
    "ff_data.rename(columns={'Unnamed: 0': 'date'}, inplace=True)\n",
    "ff_data = ff_data.iloc[:-1]\n",
    "\n",
    "# getting dates\n",
    "ff_data['date'] = ff_data['date'].astype(str).str.strip()\n",
    "\n",
    "for idx in range(len(ff_data['date'])):\n",
    "    date = ff_data.iloc[idx, 0]\n",
    "    ff_data.iloc[idx, 0] = date[:4] + '-' + date[-4:-2] + '-' + date[-2:]\n",
    "\n",
    "ff_data['date'] = pd.to_datetime(ff_data['date'])\n",
    "ff_data.set_index('date', inplace=True)\n",
    "ff_data = ff_data.loc[start_date:end_date]\n",
    "ff_data = ff_data.iloc[1:, :]\n",
    "ff_data = ff_data.apply(pd.to_numeric, errors='coerce')\n",
    "ff_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d7dbb-a66e-4e48-985c-d305ff44383e",
   "metadata": {},
   "source": [
    "### Implement the PCA Markowitz portfolio optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98865452-c6c3-4b08-b1e0-61878390423e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BR</th>\n",
       "      <th>CINF</th>\n",
       "      <th>DHI</th>\n",
       "      <th>K</th>\n",
       "      <th>LIN</th>\n",
       "      <th>BA</th>\n",
       "      <th>GLW</th>\n",
       "      <th>IDXX</th>\n",
       "      <th>LHX</th>\n",
       "      <th>O</th>\n",
       "      <th>...</th>\n",
       "      <th>BLDR</th>\n",
       "      <th>HCA</th>\n",
       "      <th>HSIC</th>\n",
       "      <th>WMB</th>\n",
       "      <th>WTW</th>\n",
       "      <th>CB</th>\n",
       "      <th>NWS</th>\n",
       "      <th>ROP</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VTRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-02</th>\n",
       "      <td>-1.727142</td>\n",
       "      <td>-0.742467</td>\n",
       "      <td>-0.073869</td>\n",
       "      <td>-0.978541</td>\n",
       "      <td>0.211179</td>\n",
       "      <td>0.969784</td>\n",
       "      <td>-0.339167</td>\n",
       "      <td>-0.763822</td>\n",
       "      <td>-0.166856</td>\n",
       "      <td>-0.795473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159984</td>\n",
       "      <td>-0.223360</td>\n",
       "      <td>-0.447511</td>\n",
       "      <td>0.825191</td>\n",
       "      <td>-0.666831</td>\n",
       "      <td>-1.245444</td>\n",
       "      <td>-0.011060</td>\n",
       "      <td>-0.968563</td>\n",
       "      <td>-0.804935</td>\n",
       "      <td>-0.530614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-06</th>\n",
       "      <td>2.043215</td>\n",
       "      <td>0.571015</td>\n",
       "      <td>-0.657904</td>\n",
       "      <td>0.155459</td>\n",
       "      <td>0.122158</td>\n",
       "      <td>0.499809</td>\n",
       "      <td>0.409046</td>\n",
       "      <td>0.344717</td>\n",
       "      <td>0.624028</td>\n",
       "      <td>0.693833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.327211</td>\n",
       "      <td>0.009781</td>\n",
       "      <td>0.688862</td>\n",
       "      <td>-0.978992</td>\n",
       "      <td>0.633751</td>\n",
       "      <td>0.223701</td>\n",
       "      <td>-1.379492</td>\n",
       "      <td>0.018777</td>\n",
       "      <td>0.573029</td>\n",
       "      <td>0.282577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>0.078249</td>\n",
       "      <td>0.612604</td>\n",
       "      <td>1.127380</td>\n",
       "      <td>1.057040</td>\n",
       "      <td>1.933386</td>\n",
       "      <td>0.617109</td>\n",
       "      <td>0.667510</td>\n",
       "      <td>1.368944</td>\n",
       "      <td>0.159112</td>\n",
       "      <td>0.384122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792951</td>\n",
       "      <td>2.244755</td>\n",
       "      <td>0.981322</td>\n",
       "      <td>0.950131</td>\n",
       "      <td>1.309531</td>\n",
       "      <td>1.060436</td>\n",
       "      <td>2.158590</td>\n",
       "      <td>2.021210</td>\n",
       "      <td>0.157975</td>\n",
       "      <td>1.304501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>-0.106986</td>\n",
       "      <td>-0.522757</td>\n",
       "      <td>-0.076313</td>\n",
       "      <td>-1.821949</td>\n",
       "      <td>-2.098169</td>\n",
       "      <td>-0.383640</td>\n",
       "      <td>-0.109007</td>\n",
       "      <td>-0.285140</td>\n",
       "      <td>-0.618065</td>\n",
       "      <td>-2.060936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408577</td>\n",
       "      <td>-1.525828</td>\n",
       "      <td>-0.205070</td>\n",
       "      <td>-1.426708</td>\n",
       "      <td>-1.097805</td>\n",
       "      <td>-0.531037</td>\n",
       "      <td>-0.958380</td>\n",
       "      <td>-1.238131</td>\n",
       "      <td>0.100072</td>\n",
       "      <td>-1.282285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>0.014320</td>\n",
       "      <td>0.142150</td>\n",
       "      <td>0.100420</td>\n",
       "      <td>1.386721</td>\n",
       "      <td>0.981101</td>\n",
       "      <td>-0.450297</td>\n",
       "      <td>0.476458</td>\n",
       "      <td>-0.131306</td>\n",
       "      <td>0.386960</td>\n",
       "      <td>2.046416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985593</td>\n",
       "      <td>-0.132906</td>\n",
       "      <td>-0.062157</td>\n",
       "      <td>2.444221</td>\n",
       "      <td>0.377253</td>\n",
       "      <td>-0.441473</td>\n",
       "      <td>1.902472</td>\n",
       "      <td>0.109256</td>\n",
       "      <td>-0.485148</td>\n",
       "      <td>0.864395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-25</th>\n",
       "      <td>-1.341237</td>\n",
       "      <td>-1.262312</td>\n",
       "      <td>-1.964281</td>\n",
       "      <td>-0.259497</td>\n",
       "      <td>-0.559419</td>\n",
       "      <td>-1.262382</td>\n",
       "      <td>0.058178</td>\n",
       "      <td>-0.820905</td>\n",
       "      <td>0.125122</td>\n",
       "      <td>-0.066254</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.294652</td>\n",
       "      <td>-0.313624</td>\n",
       "      <td>-1.579457</td>\n",
       "      <td>0.393670</td>\n",
       "      <td>-0.762384</td>\n",
       "      <td>-0.436060</td>\n",
       "      <td>-1.447994</td>\n",
       "      <td>-1.755655</td>\n",
       "      <td>-0.739933</td>\n",
       "      <td>-0.609328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-26</th>\n",
       "      <td>1.209924</td>\n",
       "      <td>0.658290</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.020543</td>\n",
       "      <td>0.911863</td>\n",
       "      <td>1.603218</td>\n",
       "      <td>-0.249047</td>\n",
       "      <td>0.207227</td>\n",
       "      <td>0.188197</td>\n",
       "      <td>0.617410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545129</td>\n",
       "      <td>0.134251</td>\n",
       "      <td>1.090775</td>\n",
       "      <td>0.440749</td>\n",
       "      <td>0.037272</td>\n",
       "      <td>0.159887</td>\n",
       "      <td>0.032654</td>\n",
       "      <td>0.061005</td>\n",
       "      <td>-0.226703</td>\n",
       "      <td>-0.153055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-27</th>\n",
       "      <td>0.042311</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>-0.069300</td>\n",
       "      <td>0.064111</td>\n",
       "      <td>-0.387889</td>\n",
       "      <td>-1.011651</td>\n",
       "      <td>-0.463999</td>\n",
       "      <td>-0.075674</td>\n",
       "      <td>-0.442119</td>\n",
       "      <td>0.490142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302649</td>\n",
       "      <td>0.399103</td>\n",
       "      <td>-0.435690</td>\n",
       "      <td>0.037065</td>\n",
       "      <td>-0.241548</td>\n",
       "      <td>0.691791</td>\n",
       "      <td>0.293646</td>\n",
       "      <td>1.097957</td>\n",
       "      <td>0.875834</td>\n",
       "      <td>0.494938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-28</th>\n",
       "      <td>-0.393696</td>\n",
       "      <td>-0.299817</td>\n",
       "      <td>0.419205</td>\n",
       "      <td>-0.181622</td>\n",
       "      <td>-0.164306</td>\n",
       "      <td>-0.051596</td>\n",
       "      <td>1.068694</td>\n",
       "      <td>0.327740</td>\n",
       "      <td>0.204697</td>\n",
       "      <td>-0.838189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143132</td>\n",
       "      <td>-0.102226</td>\n",
       "      <td>0.069880</td>\n",
       "      <td>0.109967</td>\n",
       "      <td>0.094095</td>\n",
       "      <td>-0.179433</td>\n",
       "      <td>0.143187</td>\n",
       "      <td>-0.688781</td>\n",
       "      <td>-0.573467</td>\n",
       "      <td>-0.082430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-29</th>\n",
       "      <td>-0.084115</td>\n",
       "      <td>0.217383</td>\n",
       "      <td>-0.175058</td>\n",
       "      <td>0.224141</td>\n",
       "      <td>-0.389756</td>\n",
       "      <td>-0.294080</td>\n",
       "      <td>-1.890472</td>\n",
       "      <td>-0.311126</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>1.042768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>-0.583888</td>\n",
       "      <td>0.303615</td>\n",
       "      <td>-0.525775</td>\n",
       "      <td>0.500577</td>\n",
       "      <td>0.316796</td>\n",
       "      <td>-0.166101</td>\n",
       "      <td>0.187041</td>\n",
       "      <td>1.013207</td>\n",
       "      <td>0.494938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  BR      CINF       DHI         K       LIN        BA  \\\n",
       "Date                                                                     \n",
       "2022-09-02 -1.727142 -0.742467 -0.073869 -0.978541  0.211179  0.969784   \n",
       "2022-09-06  2.043215  0.571015 -0.657904  0.155459  0.122158  0.499809   \n",
       "2022-09-07  0.078249  0.612604  1.127380  1.057040  1.933386  0.617109   \n",
       "2022-09-08 -0.106986 -0.522757 -0.076313 -1.821949 -2.098169 -0.383640   \n",
       "2022-09-09  0.014320  0.142150  0.100420  1.386721  0.981101 -0.450297   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2025-08-25 -1.341237 -1.262312 -1.964281 -0.259497 -0.559419 -1.262382   \n",
       "2025-08-26  1.209924  0.658290  0.196133  0.020543  0.911863  1.603218   \n",
       "2025-08-27  0.042311  0.028062 -0.069300  0.064111 -0.387889 -1.011651   \n",
       "2025-08-28 -0.393696 -0.299817  0.419205 -0.181622 -0.164306 -0.051596   \n",
       "2025-08-29 -0.084115  0.217383 -0.175058  0.224141 -0.389756 -0.294080   \n",
       "\n",
       "                 GLW      IDXX       LHX         O  ...      BLDR       HCA  \\\n",
       "Date                                                ...                       \n",
       "2022-09-02 -0.339167 -0.763822 -0.166856 -0.795473  ... -0.159984 -0.223360   \n",
       "2022-09-06  0.409046  0.344717  0.624028  0.693833  ... -0.327211  0.009781   \n",
       "2022-09-07  0.667510  1.368944  0.159112  0.384122  ...  0.792951  2.244755   \n",
       "2022-09-08 -0.109007 -0.285140 -0.618065 -2.060936  ... -0.408577 -1.525828   \n",
       "2022-09-09  0.476458 -0.131306  0.386960  2.046416  ...  0.985593 -0.132906   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2025-08-25  0.058178 -0.820905  0.125122 -0.066254  ... -2.294652 -0.313624   \n",
       "2025-08-26 -0.249047  0.207227  0.188197  0.617410  ...  0.545129  0.134251   \n",
       "2025-08-27 -0.463999 -0.075674 -0.442119  0.490142  ... -0.302649  0.399103   \n",
       "2025-08-28  1.068694  0.327740  0.204697 -0.838189  ... -0.143132 -0.102226   \n",
       "2025-08-29 -1.890472 -0.311126  0.044400  1.042768  ...  0.004606 -0.583888   \n",
       "\n",
       "                HSIC       WMB       WTW        CB       NWS       ROP  \\\n",
       "Date                                                                     \n",
       "2022-09-02 -0.447511  0.825191 -0.666831 -1.245444 -0.011060 -0.968563   \n",
       "2022-09-06  0.688862 -0.978992  0.633751  0.223701 -1.379492  0.018777   \n",
       "2022-09-07  0.981322  0.950131  1.309531  1.060436  2.158590  2.021210   \n",
       "2022-09-08 -0.205070 -1.426708 -1.097805 -0.531037 -0.958380 -1.238131   \n",
       "2022-09-09 -0.062157  2.444221  0.377253 -0.441473  1.902472  0.109256   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2025-08-25 -1.579457  0.393670 -0.762384 -0.436060 -1.447994 -1.755655   \n",
       "2025-08-26  1.090775  0.440749  0.037272  0.159887  0.032654  0.061005   \n",
       "2025-08-27 -0.435690  0.037065 -0.241548  0.691791  0.293646  1.097957   \n",
       "2025-08-28  0.069880  0.109967  0.094095 -0.179433  0.143187 -0.688781   \n",
       "2025-08-29  0.303615 -0.525775  0.500577  0.316796 -0.166101  0.187041   \n",
       "\n",
       "                 UNH      VTRS  \n",
       "Date                            \n",
       "2022-09-02 -0.804935 -0.530614  \n",
       "2022-09-06  0.573029  0.282577  \n",
       "2022-09-07  0.157975  1.304501  \n",
       "2022-09-08  0.100072 -1.282285  \n",
       "2022-09-09 -0.485148  0.864395  \n",
       "...              ...       ...  \n",
       "2025-08-25 -0.739933 -0.609328  \n",
       "2025-08-26 -0.226703 -0.153055  \n",
       "2025-08-27  0.875834  0.494938  \n",
       "2025-08-28 -0.573467 -0.082430  \n",
       "2025-08-29  1.013207  0.494938  \n",
       "\n",
       "[750 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df = simple_df.pct_change().dropna()\n",
    "\n",
    "norm_returns = (returns_df - returns_df.mean()) / returns_df.std()\n",
    "norm_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a7cbfb5-c7c2-4b77-b47a-505f0fb3be1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest eigenvalue: 10.38672\n",
      "Tracy–Widom statistic: 338.98111\n",
      "p-value: 0.00000e+00\n"
     ]
    }
   ],
   "source": [
    "# CHAT GPT\n",
    "\n",
    "# --- Fit PCA on your dataframe ---\n",
    "pca = PCA().fit(norm_returns)\n",
    "eigs = pca.explained_variance_        # eigenvalues (variances of each PC)\n",
    "\n",
    "# --- Get n (samples) and p (features) ---\n",
    "n, p = log_df.shape\n",
    "\n",
    "# --- Tracy–Widom scaling (Johnstone 2001) ---\n",
    "sqrt_n = np.sqrt(n)\n",
    "sqrt_p = np.sqrt(p)\n",
    "mu = (sqrt_n + sqrt_p)**2 / n\n",
    "sigma = (sqrt_n + sqrt_p) * (1/sqrt_n + 1/sqrt_p)**(1/3) / n\n",
    "\n",
    "# --- Convert sklearn’s (1/(n-1)) scaling to 1/n convention ---\n",
    "lambda1 = eigs[0] * (n - 1) / n\n",
    "\n",
    "# --- Compute TW statistic and p-value ---\n",
    "tw_stat = (lambda1 - mu) / sigma\n",
    "tw = TracyWidom(beta=1)\n",
    "pval = 1 - tw.cdf(tw_stat)\n",
    "\n",
    "print(f\"Largest eigenvalue: {lambda1:.5f}\")\n",
    "print(f\"Tracy–Widom statistic: {tw_stat:.5f}\")\n",
    "print(f\"p-value: {pval:.5e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b19f4de-8c10-4f91-b1c8-0bb0daef52c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMP     0.045439\n",
       "PNC     0.045038\n",
       "FITB    0.042291\n",
       "XYL     0.041963\n",
       "LIN     0.040284\n",
       "CINF    0.040181\n",
       "MAA     0.040013\n",
       "ROP     0.039853\n",
       "RJF     0.039435\n",
       "NWS     0.038300\n",
       "A       0.038145\n",
       "BR      0.038024\n",
       "GLW     0.034971\n",
       "BLDR    0.034252\n",
       "WTW     0.033591\n",
       "IDXX    0.033455\n",
       "O       0.033290\n",
       "WMB     0.031878\n",
       "VTRS    0.031600\n",
       "DHI     0.031257\n",
       "CB      0.030782\n",
       "SBAC    0.030419\n",
       "MTCH    0.030066\n",
       "HSIC    0.029940\n",
       "HCA     0.028890\n",
       "BA      0.028199\n",
       "LHX     0.027274\n",
       "CAH     0.021310\n",
       "K       0.011473\n",
       "UNH     0.008387\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc1 = pd.Series(pca.components_[0], index=norm_returns.columns)\n",
    "pc1 = pc1/pc1.sum()\n",
    "pc1_sorted = pc1.sort_values(ascending=False)\n",
    "pc1_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0118e144-8462-453f-af3f-494de6cb4735",
   "metadata": {},
   "source": [
    "### Implement the Fama-French three-factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f1835b8-5773-4604-930f-d0357f3ef7c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# code generated with ChatGPT\n",
    "def min_idiosyncratic_risk_portfolio(residual_cov_matrix, method='long_only'):\n",
    "    \"\"\"\n",
    "    Construct portfolio that minimizes idiosyncratic risk\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    residual_cov_matrix : array-like\n",
    "        Covariance matrix of Fama-French residuals (N x N)\n",
    "    method : str\n",
    "        'long_only' - no short selling, weights sum to 1\n",
    "        'fully_invested' - can short, weights sum to 1  \n",
    "        'dollar_neutral' - long/short, weights sum to 0\n",
    "    \"\"\"\n",
    "    N = residual_cov_matrix.shape[0]\n",
    "    \n",
    "    if method == 'long_only':\n",
    "        # No short selling constraint\n",
    "        constraints = [\n",
    "            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},  # Sum to 1\n",
    "        ]\n",
    "        bounds = [(0, 1) for _ in range(N)]  # No short selling\n",
    "        \n",
    "    elif method == 'fully_invested':\n",
    "        # Can short, but fully invested\n",
    "        constraints = [\n",
    "            {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n",
    "        ]\n",
    "        bounds = [(-1, 1) for _ in range(N)]\n",
    "        \n",
    "    elif method == 'dollar_neutral':\n",
    "        # Dollar neutral (long/short)\n",
    "        constraints = [\n",
    "            {'type': 'eq', 'fun': lambda x: np.sum(x)},  # Sum to 0\n",
    "            {'type': 'eq', 'fun': lambda x: np.sum(np.abs(x)) - 1},  # Total leverage = 1\n",
    "        ]\n",
    "        bounds = [(-1, 1) for _ in range(N)]\n",
    "    \n",
    "    # Objective function: portfolio variance = w'Σw\n",
    "    def objective(weights):\n",
    "        return weights.T @ residual_cov_matrix @ weights\n",
    "    \n",
    "    # Initial guess (equal weights)\n",
    "    x0 = np.ones(N) / N\n",
    "    \n",
    "    # Optimize\n",
    "    result = minimize(objective, x0, method='SLSQP', \n",
    "                     bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    return result.x, result.fun\n",
    "\n",
    "def idiosyncratic_risk_parity(residual_cov_matrix):\n",
    "    \"\"\"\n",
    "    Risk parity portfolio based on idiosyncratic risk\n",
    "    Each asset contributes equally to portfolio idiosyncratic risk\n",
    "    \"\"\"\n",
    "    # Get idiosyncratic variances (diagonal of covariance matrix)\n",
    "    idiosyncratic_variances = np.diag(residual_cov_matrix)\n",
    "    \n",
    "    # Risk parity weights: inverse of standard deviation\n",
    "    weights = 1 / np.sqrt(idiosyncratic_variances)\n",
    "    weights = weights / np.sum(weights)  # Normalize\n",
    "    \n",
    "    # Calculate portfolio idiosyncratic risk\n",
    "    portfolio_variance = weights.T @ residual_cov_matrix @ weights\n",
    "    \n",
    "    return weights, np.sqrt(portfolio_variance)\n",
    "\n",
    "def max_diversification_residuals(residual_cov_matrix):\n",
    "    \"\"\"\n",
    "    Maximum diversification portfolio using residual covariance matrix\n",
    "    Maximizes the diversification ratio: weighted avg vol / portfolio vol\n",
    "    \"\"\"\n",
    "    N = residual_cov_matrix.shape[0]\n",
    "    \n",
    "    # Individual idiosyncratic volatilities\n",
    "    idiosyncratic_vols = np.sqrt(np.diag(residual_cov_matrix))\n",
    "    \n",
    "    def diversification_ratio(weights):\n",
    "        portfolio_vol = np.sqrt(weights.T @ residual_cov_matrix @ weights)\n",
    "        weighted_avg_vol = weights @ idiosyncratic_vols\n",
    "        return weighted_avg_vol / portfolio_vol\n",
    "    \n",
    "    # Constraints: long only, fully invested\n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n",
    "    ]\n",
    "    bounds = [(0, 1) for _ in range(N)]\n",
    "    \n",
    "    # Negative because we maximize\n",
    "    def objective(weights):\n",
    "        return -diversification_ratio(weights)\n",
    "    \n",
    "    x0 = np.ones(N) / N\n",
    "    result = minimize(objective, x0, method='SLSQP', \n",
    "                     bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    return result.x, -result.fun\n",
    "\n",
    "def construct_residual_based_portfolio(ff_residuals_cov, expected_returns=None, \n",
    "                                     target_return=None, method='min_risk'):\n",
    "    \"\"\"\n",
    "    Complete portfolio construction from Fama-French residuals covariance\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ff_residuals_cov : DataFrame\n",
    "        Covariance matrix of Fama-French residuals\n",
    "    expected_returns : array-like, optional\n",
    "        Expected returns for mean-variance optimization\n",
    "    target_return : float, optional  \n",
    "        Target return for mean-variance optimization\n",
    "    method : str\n",
    "        'min_risk' - minimum idiosyncratic risk\n",
    "        'risk_parity' - risk parity on residuals\n",
    "        'max_diversification' - maximum diversification\n",
    "        'mean_variance' - traditional mean-variance on residuals\n",
    "    \"\"\"\n",
    "    \n",
    "    cov_matrix = ff_residuals_cov.values\n",
    "    stocks = ff_residuals_cov.columns.tolist()\n",
    "    N = len(stocks)\n",
    "    \n",
    "    if method == 'min_risk':\n",
    "        weights, risk = min_idiosyncratic_risk_portfolio(cov_matrix, 'long_only')\n",
    "        \n",
    "    elif method == 'risk_parity':\n",
    "        weights, risk = idiosyncratic_risk_parity(cov_matrix)\n",
    "        \n",
    "    elif method == 'max_diversification':\n",
    "        weights, risk = max_diversification_residuals(cov_matrix)\n",
    "        \n",
    "    elif method == 'mean_variance':\n",
    "        if expected_returns is None:\n",
    "            raise ValueError(\"Expected returns required for mean-variance optimization\")\n",
    "        if target_return is None:\n",
    "            target_return = np.mean(expected_returns)\n",
    "        \n",
    "        weights, risk = mean_variance_residuals(cov_matrix, expected_returns, target_return)\n",
    "    \n",
    "    # Create portfolio series\n",
    "    portfolio = pd.Series(weights, index=stocks, name='Weights')\n",
    "    \n",
    "    # Calculate portfolio statistics\n",
    "    portfolio_variance = weights.T @ cov_matrix @ weights\n",
    "    portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "    \n",
    "    if expected_returns is not None:\n",
    "        portfolio_return = weights @ expected_returns\n",
    "    else:\n",
    "        portfolio_return = None\n",
    "    \n",
    "    results = {\n",
    "        'weights': portfolio,\n",
    "        'idiosyncratic_volatility': portfolio_volatility,\n",
    "        'expected_return': portfolio_return,\n",
    "        'method': method\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def mean_variance_residuals(residual_cov_matrix, expected_returns, target_return):\n",
    "    \"\"\"\n",
    "    Mean-variance optimization using residual covariance matrix\n",
    "    \"\"\"\n",
    "    N = residual_cov_matrix.shape[0]\n",
    "    \n",
    "    # Objective: minimize portfolio variance\n",
    "    def objective(weights):\n",
    "        return weights.T @ residual_cov_matrix @ weights\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},  # Fully invested\n",
    "        {'type': 'eq', 'fun': lambda x: x @ expected_returns - target_return},  # Target return\n",
    "    ]\n",
    "    \n",
    "    bounds = [(0, 1) for _ in range(N)]  # Long only\n",
    "    \n",
    "    x0 = np.ones(N) / N\n",
    "    result = minimize(objective, x0, method='SLSQP', \n",
    "                     bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    portfolio_variance = result.x.T @ residual_cov_matrix @ result.x\n",
    "    \n",
    "    return result.x, np.sqrt(portfolio_variance)\n",
    "\n",
    "def construct_residual_based_portfolio(ff_residuals_cov, expected_returns=None, \n",
    "                                     target_return=None, method='min_risk'):\n",
    "    \"\"\"\n",
    "    Complete portfolio construction from Fama-French residuals covariance\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ff_residuals_cov : DataFrame\n",
    "        Covariance matrix of Fama-French residuals\n",
    "    expected_returns : array-like, optional\n",
    "        Expected returns for mean-variance optimization\n",
    "    target_return : float, optional  \n",
    "        Target return for mean-variance optimization\n",
    "    method : str\n",
    "        'min_risk' - minimum idiosyncratic risk\n",
    "        'risk_parity' - risk parity on residuals\n",
    "        'max_diversification' - maximum diversification\n",
    "        'mean_variance' - traditional mean-variance on residuals\n",
    "    \"\"\"\n",
    "    \n",
    "    cov_matrix = ff_residuals_cov.values\n",
    "    stocks = ff_residuals_cov.columns.tolist()\n",
    "    N = len(stocks)\n",
    "    \n",
    "    if method == 'min_risk':\n",
    "        weights, risk = min_idiosyncratic_risk_portfolio(cov_matrix, 'long_only')\n",
    "        \n",
    "    elif method == 'risk_parity':\n",
    "        weights, risk = idiosyncratic_risk_parity(cov_matrix)\n",
    "        \n",
    "    elif method == 'max_diversification':\n",
    "        weights, risk = max_diversification_residuals(cov_matrix)\n",
    "        \n",
    "    elif method == 'mean_variance':\n",
    "        if expected_returns is None:\n",
    "            raise ValueError(\"Expected returns required for mean-variance optimization\")\n",
    "        if target_return is None:\n",
    "            target_return = np.mean(expected_returns)\n",
    "        \n",
    "        weights, risk = mean_variance_residuals(cov_matrix, expected_returns, target_return)\n",
    "    \n",
    "    # Create portfolio series\n",
    "    portfolio = pd.Series(weights, index=stocks, name='Weights')\n",
    "    \n",
    "    # Calculate portfolio statistics\n",
    "    portfolio_variance = weights.T @ cov_matrix @ weights\n",
    "    portfolio_volatility = np.sqrt(portfolio_variance)\n",
    "    \n",
    "    if expected_returns is not None:\n",
    "        portfolio_return = weights @ expected_returns\n",
    "    else:\n",
    "        portfolio_return = None\n",
    "    \n",
    "    results = {\n",
    "        'weights': portfolio,\n",
    "        'idiosyncratic_volatility': portfolio_volatility,\n",
    "        'expected_return': portfolio_return,\n",
    "        'method': method\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def mean_variance_residuals(residual_cov_matrix, expected_returns, target_return):\n",
    "    \"\"\"\n",
    "    Mean-variance optimization using residual covariance matrix\n",
    "    \"\"\"\n",
    "    N = residual_cov_matrix.shape[0]\n",
    "    \n",
    "    # Objective: minimize portfolio variance\n",
    "    def objective(weights):\n",
    "        return weights.T @ residual_cov_matrix @ weights\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [\n",
    "        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},  # Fully invested\n",
    "        {'type': 'eq', 'fun': lambda x: x @ expected_returns - target_return},  # Target return\n",
    "    ]\n",
    "    \n",
    "    bounds = [(0, 1) for _ in range(N)]  # Long only\n",
    "    \n",
    "    x0 = np.ones(N) / N\n",
    "    result = minimize(objective, x0, method='SLSQP', \n",
    "                     bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    portfolio_variance = result.x.T @ residual_cov_matrix @ result.x\n",
    "    \n",
    "    return result.x, np.sqrt(portfolio_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78c9b9b5-93d2-4bc9-8e67-7bd953f31d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Risk Parity Portfolio:\n",
      "ROP     0.047048\n",
      "LIN     0.044330\n",
      "AMP     0.042982\n",
      "PNC     0.042852\n",
      "CB      0.040140\n",
      "BR      0.040132\n",
      "O       0.039558\n",
      "FITB    0.039160\n",
      "XYL     0.037294\n",
      "MAA     0.036477\n",
      "Name: Weights, dtype: float64\n",
      "Idiosyncratic Volatility: 0.0050\n"
     ]
    }
   ],
   "source": [
    "# get excess returns for each stock \n",
    "excess_returns = simple_df.sub(ff_data['RF'], axis=0)\n",
    "excess_returns.head()\n",
    "\n",
    "# get factors \n",
    "factors = ff_data.iloc[:, :3]\n",
    "\n",
    "# get residuals\n",
    "residuals_df = pd.DataFrame(index=excess_returns.index)\n",
    "for stock in excess_returns.columns:\n",
    "    y = excess_returns[stock].dropna()\n",
    "    x = factors.loc[y.index]\n",
    "\n",
    "    x_const = sm.add_constant(x)\n",
    "    model = sm.OLS(y, x_const).fit()\n",
    "    residuals_df[stock] = model.resid\n",
    "\n",
    "# get covariance matrix of the residuals\n",
    "residuals_clean = residuals_df.dropna(axis=1)\n",
    "covariance_matrix = residuals_clean.cov()\n",
    "\n",
    "# get a portfolio\n",
    "portfolio = construct_residual_based_portfolio(\n",
    "    covariance_matrix,\n",
    "    method='risk_parity'\n",
    ")\n",
    "\n",
    "# check portfolio\n",
    "print(\"\\nRisk Parity Portfolio:\")\n",
    "print(portfolio['weights'].sort_values(ascending=False).head(10))\n",
    "print(f\"Idiosyncratic Volatility: {portfolio['idiosyncratic_volatility']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e89a06bb-fbdc-4b87-8da6-60d130b4ff51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BR      0.040132\n",
       "CINF    0.035561\n",
       "DHI     0.023789\n",
       "K       0.036109\n",
       "LIN     0.044330\n",
       "BA      0.023810\n",
       "GLW     0.031996\n",
       "IDXX    0.023808\n",
       "LHX     0.034063\n",
       "O       0.039558\n",
       "A       0.030214\n",
       "CAH     0.033297\n",
       "FITB    0.039160\n",
       "MTCH    0.019660\n",
       "PNC     0.042852\n",
       "AMP     0.042982\n",
       "MAA     0.036477\n",
       "RJF     0.035944\n",
       "SBAC    0.026328\n",
       "XYL     0.037294\n",
       "BLDR    0.020274\n",
       "HCA     0.029116\n",
       "HSIC    0.030813\n",
       "WMB     0.036377\n",
       "WTW     0.035704\n",
       "CB      0.040140\n",
       "NWS     0.036274\n",
       "ROP     0.047048\n",
       "UNH     0.021485\n",
       "VTRS    0.025406\n",
       "Name: Weights, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = portfolio['weights']\n",
    "ff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f9ff1-a998-4257-8ed8-1eaa7b7f8b4d",
   "metadata": {},
   "source": [
    "## Intermediate Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec819c6c-ee84-400a-9627-f2e7b5623a96",
   "metadata": {},
   "source": [
    "Plan:\n",
    "1. Implement the RIE Markowitz portfolio optimization\n",
    "      - Estimate the covariance matrix by doing RIE on the log returns\n",
    "2. Check which eigenvectors are significant using Marchenco-Pastur and pick one to use for the portfolio (this should be the second largest eigenvalue).\n",
    "3. Compare its fit to the efficient frontier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18d71b5-9c68-4eb9-acab-adad71da91a6",
   "metadata": {},
   "source": [
    "### Implement the RIE Markowitz portfolio optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab69b7cb-6183-498b-8bd0-6be10c67d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute RIE-cleaned correlation matrix\n",
    "cleansed_rie = rie_estimator.get_rie(norm_returns, normalize=True, max_ones=True)\n",
    "\n",
    "# eigen-decomposition\n",
    "eigvals, eigvecs = np.linalg.eigh(cleansed_rie)\n",
    "eigvals = np.real(eigvals)\n",
    "eigvals.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b9f6d8-2d02-4087-bbc2-9c6b23f98e00",
   "metadata": {},
   "source": [
    "### Check which eigenvectors are significant using Marchenco-Pastur and pick one to use for the portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31d2f49e-b0bc-4561-af70-cb0edf718227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Marčenko–Pastur parameters\n",
    "T, N = norm_returns.shape\n",
    "q = N / T\n",
    "lambda_minus = (1 - np.sqrt(q))**2\n",
    "lambda_plus = (1 + np.sqrt(q))**2\n",
    "\n",
    "# Define MP PDF\n",
    "def mp_pdf(lmbda, q):\n",
    "    lm, lp = (1 - np.sqrt(q))**2, (1 + np.sqrt(q))**2\n",
    "    pdf = np.zeros_like(lmbda)\n",
    "    mask = (lmbda >= lm) & (lmbda <= lp)\n",
    "    pdf[mask] = np.sqrt((lp - lmbda[mask]) * (lmbda[mask] - lm)) / (2 * np.pi * q * lmbda[mask])\n",
    "    return pdf\n",
    "\n",
    "lambda_grid = np.linspace(0, max(eigvals) * 1.1, 1000)\n",
    "mp_density = mp_pdf(lambda_grid, q)\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.hist(eigvals, bins=50, density=True, alpha=0.6, label='Empirical eigenvalues')\n",
    "plt.plot(lambda_grid, mp_density, 'r-', lw=2, label='Marčenko–Pastur PDF')\n",
    "plt.axvline(lambda_minus, color='k', linestyle='--', label=r'$\\lambda_-$')\n",
    "plt.axvline(lambda_plus, color='k', linestyle='--', label=r'$\\lambda_+$')\n",
    "\n",
    "plt.title('Empirical Eigenvalue Spectrum vs Marčenko–Pastur Distribution')\n",
    "plt.xlabel('Eigenvalue')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# force x-axis ticks to integer alignment\n",
    "max_tick = int(np.ceil(max(eigvals)))\n",
    "plt.xticks(np.arange(0, max_tick + 1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ace1029-12f2-403d-99c8-52f756485952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant eigenvalues: 4\n",
      "Significant eigenvalues:\n",
      "[1.46393771 1.7518152  1.77087628 7.44319542]\n",
      "\n",
      "Shape of corresponding eigenvector matrix: (30, 4)\n",
      "(Columns correspond to significant principal components.)\n",
      "\n",
      "First significant eigenvector:\n",
      "[ 0.15679249  0.12987575 -0.05738446  0.28474759  0.06228692 -0.08383411\n",
      " -0.15270815  0.01535751  0.18438425  0.24810603 -0.05585147  0.28094808\n",
      " -0.29809858 -0.19244094 -0.24879008 -0.20805934  0.17348142 -0.24744764\n",
      "  0.20395553 -0.04692957 -0.19669261  0.13651913  0.06766576  0.03543793\n",
      "  0.24111218  0.24572445 -0.23098331  0.14576541  0.19679641 -0.02987241]\n"
     ]
    }
   ],
   "source": [
    "# identify significant eigenvalues (above the MP upper bound)\n",
    "significant_mask = eigvals > lambda_plus\n",
    "\n",
    "# extract those eigenvalues and their corresponding eigenvectors\n",
    "significant_eigvals = eigvals[significant_mask]\n",
    "significant_eigvecs = eigvecs[:, significant_mask]\n",
    "\n",
    "print(f\"Number of significant eigenvalues: {significant_eigvals.size}\")\n",
    "print(\"Significant eigenvalues:\")\n",
    "print(significant_eigvals)\n",
    "\n",
    "print(\"\\nShape of corresponding eigenvector matrix:\", significant_eigvecs.shape)\n",
    "print(\"(Columns correspond to significant principal components.)\")\n",
    "\n",
    "# inspect first significant eigenvector\n",
    "if significant_eigvals.size > 0:\n",
    "    print(\"\\nFirst significant eigenvector:\")\n",
    "    print(significant_eigvecs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c81604ac-1c9b-428c-a129-6ed001a9416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top stocks by squared-loading weights (nonnegative):\n",
      "   Stock    Weight\n",
      "0   FITB  0.088863\n",
      "1      K  0.081081\n",
      "2    CAH  0.078932\n",
      "3    PNC  0.061897\n",
      "4      O  0.061557\n",
      "5    RJF  0.061230\n",
      "6     CB  0.060381\n",
      "7    WTW  0.058135\n",
      "8    NWS  0.053353\n",
      "9    AMP  0.043289\n",
      "10  SBAC  0.041598\n",
      "11   UNH  0.038729\n",
      "12  BLDR  0.038688\n",
      "13  MTCH  0.037034\n",
      "14   LHX  0.033998\n",
      "15   MAA  0.030096\n",
      "16    BR  0.024584\n",
      "17   GLW  0.023320\n",
      "18   ROP  0.021248\n",
      "19   HCA  0.018637\n",
      "20  CINF  0.016868\n",
      "21    BA  0.007028\n",
      "22  HSIC  0.004579\n",
      "23   LIN  0.003880\n",
      "24   DHI  0.003293\n",
      "25     A  0.003119\n",
      "26   XYL  0.002202\n",
      "27   WMB  0.001256\n",
      "28  VTRS  0.000892\n",
      "29  IDXX  0.000236\n"
     ]
    }
   ],
   "source": [
    "# Assuming norm_returns is your DataFrame (T x N) with stock names as columns\n",
    "stock_names = norm_returns.columns\n",
    "\n",
    "# Take the second significant eigenvector\n",
    "v = significant_eigvecs[:, 1]\n",
    "\n",
    "# Compute squared, normalized weights\n",
    "weights_sq = v**2 / np.sum(v**2)\n",
    "\n",
    "# Combine with stock names\n",
    "stock_names = norm_returns.columns\n",
    "pc1_sq_weights = pd.DataFrame({\n",
    "    'Stock': stock_names,\n",
    "    'Weight': weights_sq\n",
    "}).sort_values(by='Weight', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Top stocks by squared-loading weights (nonnegative):\")\n",
    "print(pc1_sq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65192d-0baa-431c-a6ef-237bc7dcb3d4",
   "metadata": {},
   "source": [
    "### Compare its fit to the efficient frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de5a5654-98ab-4537-bbdf-5d7a4ef90768",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pc1_sq_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m pc1.name = \u001b[33m\"\u001b[39m\u001b[33mPC1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m ff.name = \u001b[33m\"\u001b[39m\u001b[33mFama-French\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mpc1_sq_series\u001b[49m.name = \u001b[33m\"\u001b[39m\u001b[33mRIE\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m approaches = [pc1, ff, pc1_sq_series]\n\u001b[32m      9\u001b[39m stdev_range = (\u001b[32m0.01\u001b[39m, \u001b[32m0.6\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pc1_sq_series' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Inputs ---\n",
    "# norm_returns: DataFrame of normalized returns (columns = stock tickers)\n",
    "# approaches: list of pandas Series (index = stock tickers, values = weights)\n",
    "# stdev_range: tuple (min_stdev, max_stdev)\n",
    "pc1.name = \"PC1\"\n",
    "ff.name = \"Fama-French\"\n",
    "pc1_sq_series.name = \"RIE\"\n",
    "approaches = [pc1, ff, pc1_sq_series]\n",
    "stdev_range = (0.01, 0.6)\n",
    "\n",
    "# --- Compute mean returns and covariance ---\n",
    "mean_returns = norm_returns.mean()\n",
    "cov_matrix = norm_returns.cov()\n",
    "n_assets = len(mean_returns)\n",
    "\n",
    "# --- Generate random portfolios ---\n",
    "n_portfolios = 50000\n",
    "weights = np.random.dirichlet(np.ones(n_assets), n_portfolios)\n",
    "returns = weights.dot(mean_returns.values)\n",
    "risks = np.sqrt(np.einsum('ij,jk,ik->i', weights, cov_matrix.values, weights))\n",
    "\n",
    "# --- Filter random portfolios by stdev ---\n",
    "mask = (risks >= stdev_range[0]) & (risks <= stdev_range[1])\n",
    "filtered_returns = returns[mask]\n",
    "filtered_risks = risks[mask]\n",
    "\n",
    "# --- Plot random portfolios ---\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(filtered_risks, filtered_returns, c=filtered_returns/filtered_risks,\n",
    "            cmap='viridis', s=10, alpha=0.5)\n",
    "plt.colorbar(label='Sharpe Ratio (Return/Risk)')\n",
    "\n",
    "# --- Plot approaches portfolios (all, unfiltered) ---\n",
    "for i, approach in enumerate(approaches):\n",
    "    w = approach.reindex(mean_returns.index).fillna(0).values\n",
    "    ret = np.dot(w, mean_returns.values)\n",
    "    risk = np.sqrt(np.dot(w.T, np.dot(cov_matrix.values, w)))\n",
    "    \n",
    "    # Use the Series name if available, otherwise generate default label\n",
    "    label = approach.name if approach.name else f'Portfolio {i+1}'\n",
    "    \n",
    "    plt.scatter(risk, ret, color='red', s=60, edgecolors='black', zorder=5)\n",
    "    plt.text(risk, ret, label, fontsize=9, ha='left', va='bottom')\n",
    "\n",
    "plt.title(f'Expected Return vs Risk (Random Portfolios Filtered {stdev_range[0]:.3f} ≤ σ ≤ {stdev_range[1]:.3f})')\n",
    "plt.xlabel('Risk (Standard Deviation)')\n",
    "plt.ylabel('Expected Return (Mean)')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b016f4-b162-4cbe-92f6-622980678d05",
   "metadata": {},
   "source": [
    "## Advanced Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4414633c-b66b-418c-8df5-46101568f487",
   "metadata": {},
   "source": [
    "Plan:\n",
    "As per the study done by Molero-Gonzales et al., (2023), the steps we will follow are the ff:\n",
    "1. Apply the Fama-French 3 Factor Model on the log returns matrix.\n",
    "2. Turn the coefficients for each of the factors for each stock in the portfolio into a matrix.\n",
    "3. Apply RMT.\n",
    "      - Eigenvalue decomposition\n",
    "      - Identify the significant eigenvectors using the Tracy-Widom distribution.\n",
    "4. Create a portfolio out of the significant factors and the residuals.\n",
    "5. Compare its performance against the matrix in the Basic Goal section to predict stock risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3abd6-7f6a-4046-b0d4-0bc5047e7444",
   "metadata": {},
   "source": [
    "### Apply the Fama-French 3 Factor Model on the log returns matrix.\n",
    "\n",
    "### Turn the coefficients for each of the factors for each stock in the portfolio into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979824a-016e-4093-9d4e-7c859f656fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get excess returns for each stock \n",
    "excess_returns = simple_df.sub(ff_data['RF'], axis=0)\n",
    "excess_returns.head()\n",
    "\n",
    "# get factors \n",
    "factors = ff_data.iloc[:, :3]\n",
    "\n",
    "# coefficients to matrix\n",
    "def get_stock_betas(stock_returns, factors_df):\n",
    "    \"\"\"Get factor betas for a single stock\"\"\"\n",
    "    y = stock_returns.dropna()\n",
    "    X = factors_df.loc[y.index]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return model.params[1:]\n",
    "\n",
    "# Apply to all stocks\n",
    "betas_matrix = pd.DataFrame({\n",
    "    stock: get_stock_betas(excess_returns[stock], factors)\n",
    "    for stock in excess_returns.columns\n",
    "}).T  # Transpose to have stocks as rows, factors as columns\n",
    "\n",
    "betas_matrix.columns = ['Mkt-RF_Beta', 'SMB_Beta', 'HML_Beta']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cab9127-14de-4065-9933-99b5cf64251b",
   "metadata": {},
   "source": [
    "### Apply RMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b559b-acba-479c-83d9-7b60401e7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracy_widom_threshold(N, T, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Calculate Tracy-Widom threshold for significant eigenvalues\n",
    "    \"\"\"\n",
    "    Q = T / N\n",
    "    lambda_plus = (1 + np.sqrt(1/Q))**2\n",
    "    \n",
    "    tw_percentiles = {\n",
    "        0.95: 0.98,\n",
    "        0.99: 2.02, \n",
    "        0.999: 3.27\n",
    "    }\n",
    "    \n",
    "    tw_critical = tw_percentiles.get(confidence, 0.98)\n",
    "    threshold = lambda_plus + (tw_critical * N**(-2/3))\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "def sequential_tracy_widom_test(eigenvalues, N, T, confidence=0.95):\n",
    "    \"\"\"\n",
    "    Sequential Tracy-Widom test: test each eigenvalue after removing previous ones\n",
    "    \"\"\"\n",
    "    significant_eigenvalues = []\n",
    "    remaining_eigenvalues = eigenvalues.copy()\n",
    "    \n",
    "    for i in range(len(eigenvalues)):\n",
    "        if len(remaining_eigenvalues) == 0:\n",
    "            break\n",
    "            \n",
    "        # Test the largest remaining eigenvalue\n",
    "        current_lambda = remaining_eigenvalues[0]\n",
    "        current_N = len(remaining_eigenvalues)  # Reduced dimension\n",
    "        current_T = T  # Observations stay the same\n",
    "        \n",
    "        threshold = tracy_widom_threshold(current_N, current_T, confidence)\n",
    "        \n",
    "        if current_lambda > threshold:\n",
    "            significant_eigenvalues.append(current_lambda)\n",
    "            # Remove this eigenvalue and continue\n",
    "            remaining_eigenvalues = remaining_eigenvalues[1:]\n",
    "        else:\n",
    "            # Stop when we find first non-significant eigenvalue\n",
    "            break\n",
    "    \n",
    "    return significant_eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57865dfd-130e-4073-9d8b-586578f0e62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalue decomposition\n",
    "correlation_matrix = betas_matrix.corr()\n",
    "eigenvalues_scipy, eigenvectors_scipy = eigh(correlation_matrix)\n",
    "sort_idx = np.argsort(eigenvalues_scipy)[::-1]\n",
    "eigenvalues_scipy = eigenvalues_scipy[sort_idx]\n",
    "\n",
    "N = len(betas_matrix.columns)  # 3 factors\n",
    "T = len(betas_matrix.index)    # 30 stocks\n",
    "\n",
    "# Identify the significant eigenvectors using the Tracy-Widom distribution.\n",
    "significant_eigenvalues = sequential_tracy_widom_test(\n",
    "    eigenvalues_scipy, N, T, confidence=0.95\n",
    ")\n",
    "\n",
    "print(\"Sequential Tracy-Widom Test Results:\")\n",
    "print(f\"Significant eigenvalues: {len(significant_eigenvalues)}\")\n",
    "for i, val in enumerate(significant_eigenvalues):\n",
    "    print(f\"λ_{i+1}: {val:.4f} **\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b767f60-13d2-4ee1-b375-fe67f10e5166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if your sample size is sufficient\n",
    "print(f\"Observations per stock: {T}\")\n",
    "print(\"Generally need T > 100 for stable factor estimates\")\n",
    "\n",
    "# Check the p-values from your original regressions\n",
    "for stock in betas_matrix.index[:3]:\n",
    "    y = excess_returns[stock].dropna()\n",
    "    X = factors.loc[y.index]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    print(f\"\\n{stock} regression p-values:\")\n",
    "    print(model.pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc311603-e630-46ca-86ba-346f5e551dbf",
   "metadata": {},
   "source": [
    "Based on the results above, there are no statistically significant relationships between the factor betas.\n",
    "The sample size chosen was too small to reliably estimate the style factor exposures. \n",
    "The market factor is strong, but the style factos are too noisy with only three observations. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
